diff -Naur a/etc/ansible/roles/os_trove/files/trove-diskreorder.patch b/etc/ansible/roles/os_trove/files/trove-diskreorder.patch
--- a/etc/ansible/roles/os_trove/files/trove-diskreorder.patch	1970-01-01 00:00:00.000000000 +0000
+++ b/etc/ansible/roles/os_trove/files/trove-diskreorder.patch	2017-02-04 15:14:54.592049775 +0000
@@ -0,0 +1,108 @@
+diff -Naur a/openstack/venvs/trove-14.0.6/lib/python2.7/site-packages/trove/taskmanager/models.py b/openstack/venvs/trove-14.0.6/lib/python2.7/site-packages/trove/taskmanager/models.py
+--- a/openstack/venvs/trove-14.0.6/lib/python2.7/site-packages/trove/taskmanager/models.py	2017-02-04 04:53:18.828223321 +0000
++++ b/openstack/venvs/trove-14.0.6/lib/python2.7/site-packages/trove/taskmanager/models.py	2017-02-04 04:46:25.142383299 +0000
+@@ -799,14 +799,27 @@
+         LOG.debug("Begin _create_server_volume_individually for id: %s" %
+                   self.id)
+         server = None
+-        volume_info = self._build_volume_info(datastore_manager,
++
++        #KVM disk re-order problem
++        volume_info1 = self._build_volume_info(datastore_manager,
++                                              volume_size=volume_size,
++                                              volume_type=volume_type,
++                                              device_name='vdb')
++        volume_info2 = self._build_volume_info(datastore_manager,
+                                               volume_size=volume_size,
+-                                              volume_type=volume_type)
+-        block_device_mapping = volume_info['block_device']
++                                              volume_type=volume_type,
++                                              device_name='vdc')
++        block_device_mapping1 = volume_info1['block_device']
++        block_device_mapping2 = volume_info2['block_device']
++
++        mybdm = dict(block_device_mapping1.items() + block_device_mapping2.items())
++
++        LOG.debug("PTROVE: block map: %s" % mybdm)
++
+         try:
+             server = self._create_server(flavor_id, image_id, security_groups,
+                                          datastore_manager,
+-                                         block_device_mapping,
++                                         mybdm,
+                                          availability_zone, nics, files,
+                                          scheduler_hints)
+             server_id = server.id
+@@ -818,19 +831,27 @@
+             self._log_and_raise(e, msg, err)
+         LOG.debug("End _create_server_volume_individually for id: %s" %
+                   self.id)
+-        return volume_info
++        return volume_info1
+ 
+     def _build_volume_info(self, datastore_manager, volume_size=None,
+-                           volume_type=None):
++                           volume_type=None, device_name=None):
++
+         volume_info = None
+         volume_support = self.volume_support
+-        device_path = self.device_path
++
++        if device_name:
++            LOG.debug("PTROVE: dev name %s" % device_name)
++            device_path = "/dev/" + device_name
++        else:
++            LOG.debug("PTROVE: dev name %s" % device_name)
++            device_path = self.device_path
++
+         mount_point = CONF.get(datastore_manager).mount_point
+         LOG.debug("trove volume support = %s" % volume_support)
+         if volume_support:
+             try:
+                 volume_info = self._create_volume(
+-                    volume_size, volume_type, datastore_manager)
++                    volume_size, volume_type, datastore_manager, device_name)
+             except Exception as e:
+                 msg = _("Failed to create volume for instance %s") % self.id
+                 err = inst_models.InstanceTasks.BUILDING_ERROR_VOLUME
+@@ -860,7 +881,7 @@
+         full_message = "%s%s" % (message, exc_message)
+         raise TroveError(message=full_message)
+ 
+-    def _create_volume(self, volume_size, volume_type, datastore_manager):
++    def _create_volume(self, volume_size, volume_type, datastore_manager, device_name):
+         LOG.debug("Begin _create_volume for id: %s" % self.id)
+         volume_client = create_cinder_client(self.context)
+         volume_desc = ("datastore volume for %s" % self.id)
+@@ -882,20 +903,27 @@
+         if v_ref.status in ['error']:
+             raise VolumeCreationFailure()
+         LOG.debug("End _create_volume for id: %s" % self.id)
+-        return self._build_volume(v_ref, datastore_manager)
++        return self._build_volume(v_ref, datastore_manager, device_name)
+ 
+-    def _build_volume(self, v_ref, datastore_manager):
++    def _build_volume(self, v_ref, datastore_manager, device_name):
+         LOG.debug("Created volume %s" % v_ref)
+         # The mapping is in the format:
+         # <id>:[<type>]:[<size(GB)>]:[<delete_on_terminate>]
+         # setting the delete_on_terminate instance to true=1
+         mapping = "%s:%s:%s:%s" % (v_ref.id, '', v_ref.size, 1)
+-        bdm = CONF.block_device_mapping
++
++        #KVM disk re-order problem
++        #bdm = CONF.block_device_mapping
++        bdm = device_name
++
+         block_device = {bdm: mapping}
+         created_volumes = [{'id': v_ref.id,
+                             'size': v_ref.size}]
+ 
+-        device_path = self.device_path
++        #KVM disk re-order problem
++        # device_path = self.device_path
++        device_path = "/dev/"+device_name
++
+         mount_point = CONF.get(datastore_manager).mount_point
+ 
+         LOG.debug("block_device = %(device)s\n"
